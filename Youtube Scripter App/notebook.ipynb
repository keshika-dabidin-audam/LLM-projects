{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc50dc07",
   "metadata": {},
   "source": [
    "# Automating YouTube Script Writing with LangChain and Streamlit\n",
    "\n",
    "LangChain is a natural language processing capability that generates high-quality, human-like language.\n",
    "In this project, we will build a youtube script-generating tool using LangChain and Streamlit.\n",
    "\n",
    "The application‚Äôs interface is designed using Streamlit, which provides a user-friendly experience for the creators. \n",
    "\n",
    "The application‚Äôs prompt templates and chat history storage capabilities make it easy for creators to **customize the generated scripts** to their specific needs. Moreover, the language model generates not only the script but also the **video title**, making the tool a comprehensive solution for YouTube creators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b5b8e8",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "### 1. Background & Problem Statment\n",
    "### 2. Setting Up Working Environment\n",
    "### 3. Building the Application\n",
    "3.1. Setting the Application Interface\n",
    "3.2. Setting Prompt Template\n",
    "3.3. Storing Chat History\n",
    "3.4. Set up instances of the LLMChain to generate title & script\n",
    "3.5. Printing the Generated Script\n",
    "### 4. Running the Application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b75b95",
   "metadata": {},
   "source": [
    "## 1. Background & Problem Statment\n",
    "\n",
    "### 1.1. What is LangChain & What it is used for?\n",
    "\n",
    "LangChain is a framework built around LLMs. It can be used for chatbots, Generative Question-Answering (GQA), summarization, and much more. The core idea of the library is that we can ‚Äúchain‚Äù together different components to create more advanced use cases around LLMs. Chains may consist of multiple components from several modules:\n",
    "\n",
    "- **Prompt templates**: Prompt templates are templates for different types of - prompts. Like ‚Äúchatbot‚Äù style templates, ELI5 question-answering, etc\n",
    "- **LLMs**: Large language models like GPT-3, BLOOM, etc\n",
    "- **Agents**: Agents use LLMs to decide what actions should be taken. Tools like web search or calculators can be used, and all are packaged into a logical loop of operations.\n",
    "- **Memory**: Short-term memory, long-term memory.\n",
    "\n",
    "### 1.2. Project Overview\n",
    "In this project, we will build a youtube video writing assistant that will help youtube creators in building their video scripts in less time. You will give the application the topic you would like to create a video on and it will generate a title and the script for the video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4651c632",
   "metadata": {},
   "source": [
    "## Setting up Working Environment\n",
    "Let's first start by creating a new environment called writing_assistant using this command:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38e0e3a7",
   "metadata": {},
   "source": [
    "python -m venv writing_assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe6cfb2",
   "metadata": {},
   "source": [
    "After creating the environment you can activate it using the following command:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0445443",
   "metadata": {},
   "source": [
    ".\\writing_assistant\\scripts\\activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12ef6f",
   "metadata": {},
   "source": [
    "Finally, you can download all the requirements that will need throughout the project using the following command:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "176cbaf9",
   "metadata": {},
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d85cd",
   "metadata": {},
   "source": [
    "Let's load the libraries and packages we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e622ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries & packages\n",
    "import os \n",
    "import streamlit as st \n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain \n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.utilities import WikipediaAPIWrapper \n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = apikey # your OpenAI api key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10fb6b",
   "metadata": {},
   "source": [
    "## 3. Building the Application \n",
    "### 3.1. Setting the Application Interface\n",
    "First we setup the application layout using the streamlit functions: title, image, and text_input as shown in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f6251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlet App framework\n",
    "st.title('ü¶úüîó YouTube Script Assistant') # setting teh title \n",
    "st.image('./Youtube.png') # set the featured image of the web application \n",
    "prompt = st.text_input('Plug in your prompt here')  # The box for the text prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba75ff4",
   "metadata": {},
   "source": [
    "- The first line sets the title of the web application to ‚Äúü¶úüîó YouTube Script Assistant‚Äù using the st.title() function.\n",
    "- The second line uses the st.image() function to display an image in the web application. It loads the image from the file path \"./Youtube.png\".\n",
    "- The third line creates a text input box where users can enter their input. The st.text_input() function takes a string argument that serves as the label for the input box. In this case, the label is \"Plug in your prompt here\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee8c85",
   "metadata": {},
   "source": [
    "### 3.2. Setting Prompt Template\n",
    "Next, we will set up the prompt template we will make the default template write me a youtube video title about and you will only add the topic that you would like the application to generate the script about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt templates\n",
    "title_template = PromptTemplate(\n",
    "    input_variables = ['topic'], \n",
    "    template='write me a youtube video title about {topic}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dbbaa8",
   "metadata": {},
   "source": [
    "Also, we would like to leverage Wikipedia research for the given title and we can do this using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt templates\n",
    "\n",
    "script_template = PromptTemplate(\n",
    "    input_variables = ['title', 'wikipedia_research'], \n",
    "    template='write me a youtube video script based on this title TITLE: {title} while leveraging this wikipedia reserch:{wikipedia_research} '\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634bcc5c",
   "metadata": {},
   "source": [
    "### 3.3. Storing Chat History\n",
    "Next, we will save the history of the results so if you would like to see the previous results use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_memory = ConversationBufferMemory(input_key='topic', memory_key='chat_history')\n",
    "script_memory = ConversationBufferMemory(input_key='title', memory_key='chat_history')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393f9e43",
   "metadata": {},
   "source": [
    "We first get the title of the memory which is the topic we asked the application to write the script for and then we get the generated script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e1a5a",
   "metadata": {},
   "source": [
    "### 3.4. Set up instances of the LLMChain to generate title & script\n",
    "Next, we would like to use langchain to generate the script. First, we will define two instances of the LLMChain class, which is a custom class used to generate text prompts and responses using a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235c0a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llms\n",
    "llm = OpenAI(temperature=0.9) \n",
    "title_chain = LLMChain(llm=llm, prompt=title_template, verbose=True, output_key='title', memory=title_memory)\n",
    "script_chain = LLMChain(llm=llm, prompt=script_template, verbose=True, output_key='script', memory=script_memory)\n",
    "\n",
    "wiki = WikipediaAPIWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a5908a",
   "metadata": {},
   "source": [
    "- The first line creates an instance of the OpenAI class with temperature=0.9. This sets the temperature of the language model to 0.9, which affects the creativity of the generated text. The instance of OpenAI is stored in the variable llm.\n",
    "\n",
    "- The second line creates an instance of the LLMChain class with llm=llm, prompt=title_template, verbose=True, and memory=title_memory. This instance is named title_chain and is used to generate a title based on a template. The prompt argument is the prompt template object created earlier that specifies the format of the title. The verbose argument is set to True, which means that information about the text generation process will be printed on the console. The memory argument is set to the title_memory instance, which means that the conversation history for title generation will be stored in that buffer.\n",
    "\n",
    "- The third line creates another instance of the LLMChain class with llm=llm, prompt=script_template, verbose=True, and memory=script_memory. This instance is named script_chain and is used to generate a script based on a template. Similar to title_chain, the prompt argument is set to the prompt template object for script generation, verbose is set to True, and memory is set to the script_memory instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fee099",
   "metadata": {},
   "source": [
    "### Printing the Generated Script\n",
    "Finally, we would like to print the generated script if there is an input prompt. There will be three main generated texts:\n",
    "\n",
    "- Title: This is a suggested title for the video\n",
    "- Script: This is the generated script\n",
    "- Wiki search: This is a Wikipedia research on the given topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f18e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the generated script to the screen if there's an input prompt\n",
    "if prompt: \n",
    "    title = title_chain.run(prompt)\n",
    "    wiki_research = wiki.run(prompt) \n",
    "    script = script_chain.run(title=title, wikipedia_research=wiki_research)\n",
    "\n",
    "    st.write(title) \n",
    "    st.write(script) \n",
    "\n",
    "    with st.expander('Title History'): \n",
    "        st.info(title_memory.buffer)\n",
    "\n",
    "    with st.expander('Script History'): \n",
    "        st.info(script_memory.buffer)\n",
    "\n",
    "    with st.expander('Wikipedia Research'): \n",
    "        st.info(wiki_research)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f5eff3",
   "metadata": {},
   "source": [
    "\n",
    "- The first line checks whether prompt is defined, which means that the user has entered a prompt. If prompt is defined, the application generates a title and a script using the title_chain and script_chain instances of the LLMChain class.\n",
    "\n",
    "- The title_chain.run(prompt) method generates a title based on the prompt entered by the user, and the wiki.run(prompt) method retrieves Wikipedia research data based on the same prompt. These two outputs are then passed as input to the script_chain.run(title=title, wikipedia_research=wiki_research) method, which generates the script.\n",
    "\n",
    "- The generated title and script are then displayed on the screen using the st.write() method.\n",
    "\n",
    "- The next three blocks of code create expanders using st.expander(), which allow the user to view the conversation history for the title, script, and Wikipedia research.\n",
    "\n",
    "- The conversation history is displayed using the st.info() method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efb5287",
   "metadata": {},
   "source": [
    "### 4. Running the application\n",
    "Now the application is ready to run it. To run the application you can run the following command using the command line in the project directory:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e198b940",
   "metadata": {},
   "source": [
    "streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48db13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
